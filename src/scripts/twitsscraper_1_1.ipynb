{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kPBkkHcOt4Kb"
      },
      "outputs": [],
      "source": [
        "# pip install requests bs4 pandas firebase-admin\n",
        "# !pip install pytwits # Needs token, uses API, limited accesses, can't access old stuff in order"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1gbDEb2iHEA",
        "outputId": "9952dd2f-0687-490c-aae6-e0b6c547cf5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F_KJI33tt4Kg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "import csv\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E2ln56Yt4Kh"
      },
      "source": [
        "Initialize Firestore DB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_FIRESTORE_KEY = \"\" # Generate a JSON key from the firestore website\n",
        "FILE_FOR_STORING_POSTS = \"\" # Make a CSV file for this"
      ],
      "metadata": {
        "id": "dQE-QIlFu26f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4jgQOYVnt4Kj"
      },
      "outputs": [],
      "source": [
        "#load in firestore credentials\n",
        "# https://firebase.google.com/docs/firestore/quickstart\n",
        "# DON\"T FORGET TO DELETE THE PATH WHEN PUSHING TO GITHUB!!!!\n",
        "cred = credentials.Certificate(PATH_TO_FIRESTORE_KEY)\n",
        "app = firebase_admin.initialize_app(cred)\n",
        "db = firestore.client()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just testing this out\n",
        "collection = db.collection('twit')\n",
        "document = collection.document('startIndex')\n",
        "print(document.get().to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXPmqcrLl49L",
        "outputId": "03988ece-e300-465a-f63e-545ca2fb783b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'index': 0, 'testIndex': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlhRMgVXt4Kj"
      },
      "source": [
        "This is what I would be storing for each twit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ewi05F77t4Kk"
      },
      "outputs": [],
      "source": [
        "# twit_url = \"https://stocktwits.com/user/message/497084294\"\n",
        "# print('url: ', twit_url)\n",
        "# page = requests.get(twit_url)\n",
        "# soup = BeautifulSoup(page.content, 'html.parser')\n",
        "# twit_text = str(soup.head.find(\"meta\", attrs={\"name\" : \"description\"})[\"content\"]) # This still works work\n",
        "# print('text: ', twit_text)\n",
        "# twit_user = str(soup.head.find(\"meta\", attrs={\"name\" : \"twitter:title\"})[\"content\"]).replace(' | Stocktwits','') # This no longer works\n",
        "# print('user: ', twit_user)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twit_url = \"https://stocktwits.com/user/message/802\"\n",
        "page = requests.get(twit_url)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "print(soup.head.find(\"title\").contents[0])\n",
        "\n",
        "# post_contents = soup.body.find(\"script\", attrs={\"id\" : \"__NEXT_DATA__\"})\n",
        "# json_contents = json.loads(post_contents.contents[0])\n",
        "# post_body = json_contents['props']['pageProps']['initialData']['message']['body']\n",
        "# print(post_body)\n",
        "# post_user = json_contents['props']['pageProps']['initialData']['message']['user']['username']\n",
        "# print(post_user)\n",
        "\n",
        "# Do we need to store twit URL and user URL? Those can be generated, and add much space\n",
        "# Is this good?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5T4mo80pvYW",
        "outputId": "300e31ee-dbbf-43ea-a750-55fc3094877a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This message does not exist | Stocktwits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing writing to CSV file\n",
        "with open(FILE_FOR_STORING_POSTS, 'a') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([10001, \"greenskeptic\", \"$JCI only stock in my portfolio showing green today, and then only +.31. Will try to forget this day ever happened.\"])"
      ],
      "metadata": {
        "id": "p4CvTwnJuyjm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crawls 1000 messages, takes a bit over 5 minutes on Google Colab, puts messages in a vector\n",
        "# May or may not fail\n",
        "\n",
        "messages_to_crawl = 1000\n",
        "messages = [None] * messages_to_crawl\n",
        "users = [None] * messages_to_crawl\n",
        "message_numbers = [None] * messages_to_crawl\n",
        "\n",
        "post_num = 0\n",
        "crawled_num = 0\n",
        "start = time.time()\n",
        "while (crawled_num < messages_to_crawl):\n",
        "    post_num += 1\n",
        "    post_url = \"https://stocktwits.com/user/message/\" + str(post_num)\n",
        "    page = requests.get(post_url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "    if soup.head.find(\"title\").contents[0] == \"This message does not exist | Stocktwits\":\n",
        "        continue\n",
        "    else:\n",
        "        post_contents = soup.body.find(\"script\", attrs={\"id\" : \"__NEXT_DATA__\"})\n",
        "        json_contents = json.loads(post_contents.contents[0])\n",
        "        post_body = json_contents['props']['pageProps']['initialData']['message']['body']\n",
        "        messages[crawled_num] = post_body\n",
        "        post_user = json_contents['props']['pageProps']['initialData']['message']['user']['username']\n",
        "        users[crawled_num] = post_user\n",
        "        message_numbers[crawled_num] = post_num\n",
        "        crawled_num += 1\n",
        "\n",
        "        if crawled_num % 50 == 0:\n",
        "            print(post_num, crawled_num)\n",
        "end = time.time()\n",
        "\n",
        "print(end - start)\n",
        "\n",
        "print(messages[999])\n",
        "print(users[999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hImonEk0cGlu",
        "outputId": "7a4d57e8-5ee3-483b-bb0e-e5f88a6706be"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92 50\n",
            "171 100\n",
            "244 150\n",
            "299 200\n",
            "370 250\n",
            "459 300\n",
            "541 350\n",
            "623 400\n",
            "698 450\n",
            "800 500\n",
            "891 550\n",
            "990 600\n",
            "1067 650\n",
            "1151 700\n",
            "1230 750\n",
            "1307 800\n",
            "1411 850\n",
            "1489 900\n",
            "1592 950\n",
            "1679 1000\n",
            "314.3927114009857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crawls 1000 messages, appends them to the CSV file whose location you specified \n",
        "# May or may not fail\n",
        "messages_to_crawl = 1000\n",
        "with open(FILE_FOR_STORING_POSTS, 'a') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"id\", \"post_author\", \"post_contents\"])\n",
        "\n",
        "    post_num = 0\n",
        "    crawled_num = 0\n",
        "    start = time.time()\n",
        "    while (crawled_num < messages_to_crawl):\n",
        "        post_num += 1\n",
        "        post_url = \"https://stocktwits.com/user/message/\" + str(post_num)\n",
        "        page = requests.get(post_url)\n",
        "        soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "        if soup.head.find(\"title\").contents[0] == \"This message does not exist | Stocktwits\":\n",
        "            continue\n",
        "        else:\n",
        "            post_contents = soup.body.find(\"script\", attrs={\"id\" : \"__NEXT_DATA__\"})\n",
        "            json_contents = json.loads(post_contents.contents[0])\n",
        "            post_contents = json_contents['props']['pageProps']['initialData']['message']['body']\n",
        "\n",
        "            post_author = json_contents['props']['pageProps']['initialData']['message']['user']['username']\n",
        "\n",
        "            writer.writerow([post_num, post_author, post_contents])\n",
        "\n",
        "            crawled_num += 1\n",
        "\n",
        "            if crawled_num % 50 == 0:\n",
        "                print(post_num, crawled_num)\n",
        "    end = time.time()\n",
        "\n",
        "    print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RFFUI5j0k4W",
        "outputId": "7ee19645-f698-48ff-fea5-db7b54e07c6b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "891 50\n",
            "990 100\n",
            "37.56579279899597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stuff below was made by William"
      ],
      "metadata": {
        "id": "q9XjxRFYM0HS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niLAtE5ht4Km"
      },
      "source": [
        "Example on how to get data - get our index flag for last message scraped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUN4oGbLt4Km",
        "outputId": "e9a3d989-5674-49c9-b534-ba759be3e448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document data: {'testIndex': 1, 'index': 0}\n"
          ]
        }
      ],
      "source": [
        "# we would first start by retrieving the last good message id\n",
        "doc_ref = db.collection(u'twit').document(u'startIndex')\n",
        "# https://firebase.google.com/docs/firestore/query-data/get-data\n",
        "doc = doc_ref.get()\n",
        "if doc.exists:\n",
        "    print(f'Document data: {doc.to_dict()}')\n",
        "else:\n",
        "    print(u'No such document!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPr2o82Kt4Ko"
      },
      "source": [
        "Example on how to push data - updating our index flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmDrwTbqt4Ko",
        "outputId": "4c4716f8-7c1d-4c76-cc25-cc82b987380f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1668814840\n",
              "  nanos: 26139000\n",
              "}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = {\n",
        "    u'testIndex': 10,\n",
        "}\n",
        "# https://firebase.google.com/docs/firestore/manage-data/add-data\n",
        "# Updating our doc_ref from above to whatever we specify in data.index\n",
        "doc_ref.set(data, merge=True)\n",
        "# Check if it worked by replaying above get data example and see if it changed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypYTZX_et4Kp"
      },
      "source": [
        "Next steps for creating the actual scraper:\n",
        "1. Loop through starting at index\n",
        "2. https://stocktwits.com/message/# -> # should be the index\n",
        "3. Use bs4 and add current data to csv as new row\n",
        "4. End loop when no more new messages ~ will need to talk with team on how to determine this\n",
        "5. Update index to what first bad index was\n",
        "6. Push csv to storage - I will add this code in soon\n",
        "7. End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU0X5NPmt4Kq"
      },
      "outputs": [],
      "source": [
        "#this is example\n",
        "headers = ['id', 'twit_url', 'twit_text', 'twit_user', 'twit_user_url']\n",
        "data = []\n",
        "#change range for more samples if needed\n",
        "for i in range(250):\n",
        "    twit_url = \"https://stocktwits.com/message/\" + str(i)\n",
        "    page = requests.get(twit_url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    twit_text = str(soup.head.find(\"meta\", attrs={\"name\" : \"description\"})[\"content\"]).replace(',','')\n",
        "    twit_user = str(soup.head.find(\"meta\", attrs={\"name\" : \"twitter:title\"})[\"content\"]).replace(' | Stocktwits','')\n",
        "    twit_user_url = 'https://stocktwits.com/'+twit_user.replace('@','')\n",
        "    if twit_user != '@':\n",
        "        data.append([i, twit_url, twit_text, twit_user, twit_user_url])\n",
        "#change name if wanting multiple example csvs\n",
        "with open('../csv/example.csv', 'w+') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(headers)\n",
        "    writer.writerows(data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.9 32-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e50dc8488029f96428793669918385f9dfe9ccd1ee63fdcf1feb04d8da3685d6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}